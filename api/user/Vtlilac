{"elo": 2900, "messages": [["[22:00:24]  vtlilac: Ever heard of Piper? it's a new tts thing that can even run on a raspberry pi", 204], ["[22:36:58]  vtlilac: just try how a high end machine performs on neuro stuff on GCP/Runpod?", 190], ["[22:08:35]  vtlilac: is all of neuro running on your 4090 or is it living somewhere in some server?", 180], ["[22:22:25]  vtlilac: you are using a LSTM for her. have you considered using a transformer?", 171], ["[22:32:01]  vtlilac: Are you scared for neuro now that meta released their newest LLM for free?", 170], ["[22:23:22]  vtlilac: just use google chrome remote desktop while you are not at home?", 163], ["[22:37:57]  vtlilac: Runpod and Lambda cloud are cheapest right now. Lambda cloud does like less than 2$ for an H100 for an hour", 160], ["[22:54:11]  vtlilac: intel uhd can't even train unless ur using the really bad intel oneapi thing", 153], ["[22:24:48]  vtlilac: check the output shapes of both layers that are concatenated?", 145], ["[22:17:41]  vtlilac: Vedal have you ever considered making her play microsoft flight simulator?", 142], ["[23:03:22]  vtlilac: Are you using tensorfloat32 format? How about Mixed precision?", 134], ["[22:34:18]  vtlilac: just buy an H100 gpu cluster for 200k$ smh", 125], ["[23:36:57]  vtlilac: just use a image to icon online converter", 123], ["[23:12:06]  vtlilac: Are you using tensorfloat32? Do NOT use Swap. Doesn't Nvidia starting from pascal architecture have the page migration engine? Cheer100 Cheer100 Cheer100", 112], ["[22:33:01]  vtlilac: ur motherboard and cpu do support it", 111], ["[23:22:35]  vtlilac: there's this thing called porolog++ or something", 103], ["[22:39:42]  vtlilac: linux is faster for training usually", 95], ["[22:06:02]  vtlilac: how about live rvc with streamed output from the LLM or whatever you use for neuro? that runs in real time but needs a ton of training data Cheer100 Cheer100 Cheer100", 92], ["[22:03:12]  vtlilac: just get an 8x Nvidia Tesla H100 cluster smh... or there's also this thing called Piper TTS that can even run on a raspberry pi with basically 0 latency and can be trained on custom voices Cheer100 Cheer100 Cheer100", 88], ["[21:48:09]  vtlilac: Neuro-sama vrchat integration when??", 64], ["[22:35:03]  vtlilac: let linus build you a pc", 52], ["[22:23:52]  vtlilac: just remote into your pc?", 49], ["[22:33:24]  vtlilac: Get a 13900k with ddr4", 30], ["[23:41:20]  vtlilac: bro got trolled lmao", 20], ["[21:41:17]  vtlilac: Based", 1], ["[21:49:44]  vtlilac: BRUH", 1], ["[23:01:10]  vtlilac: 9+10", 1], ["[23:02:37]  vtlilac: No", 1], ["[23:09:54]  vtlilac: aware", 1], ["[23:14:12]  vtlilac: HUH", 1], ["[22:03:06]  vtlilac: I love unity", 1], ["[22:05:53]  vtlilac: 100neuros", 1], ["[21:57:51]  vtlilac: anny mariage", 1], ["[22:15:09]  vtlilac: LMAO", 1], ["[22:16:48]  vtlilac: L", 1], ["[22:18:34]  vtlilac: \"i think\" BRUH", 1], ["[22:27:17]  vtlilac: it' on github", 1], ["[22:31:05]  vtlilac: corpa", 1], ["[22:31:34]  vtlilac: just use tensorflow smh", 1], ["[22:38:52]  vtlilac: LMAO Aware", 1], ["[22:41:33]  vtlilac: Vedal x Anny plush", 1], ["[23:22:05]  vtlilac: nosql database", 1], ["[23:29:25]  vtlilac: ebay scalper", 1], ["[23:50:11]  vtlilac: AYO", 1], ["[23:25:20]  vtlilac: pog", 1], ["[23:31:04]  vtlilac: meow", 1], ["[21:23:05]  vtlilac: OMEGA", 1], ["[21:23:27]  vtlilac: KEKW", 1]], "ranking": 1322}